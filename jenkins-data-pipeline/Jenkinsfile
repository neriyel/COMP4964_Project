// Jenkins Pipeline for AWS Data Pipeline Deployment
// Implements Infrastructure as Code using SAM (Serverless Application Model)

pipeline {
    agent any
    
    environment {
        AWS_REGION = 'us-west-2'
        STACK_NAME = 'data-pipeline-stack'
        ENVIRONMENT = 'dev'
        S3_DEPLOY_BUCKET = 'jenkins-sam-artifacts-195275680578-20251125123539'
        AWS_DEFAULT_REGION = 'us-west-2'
    }
    
    stages {
        stage('Checkout') {
            steps {
                echo 'ðŸ”„ Checking out code from GitHub...'
                checkout scm
            }
        }
        
        stage('Build') {
            steps {
                echo 'ðŸ—ï¸ Validating SAM template...'
                sh '''
                    echo "Checking template.yaml exists..."
                    ls -la jenkins-data-pipeline/template.yaml
                    echo "Template validated!"
                '''
            }
        }
        
        stage('Package') {
            steps {
                echo 'ðŸ“¦ Preparing for deployment...'
                sh '''
                    echo "Using pre-built template..."
                    cp jenkins-data-pipeline/template.yaml ./packaged.yaml
                    echo "Ready to deploy!"
                '''
            }
        }
        
        stage('Deploy') {
            steps {
                echo 'ðŸš€ Deploying to AWS...'
                sh '''
                    echo "Installing dependencies..."
                    apt-get update > /dev/null 2>&1
                    apt-get install -y python3 python3-pip > /dev/null 2>&1 || true
                    
                    echo "Installing boto3 (AWS SDK for Python)..."
                    python3 -m pip install --quiet boto3 2>/dev/null || pip3 install --quiet boto3 || true
                    
                    echo "Running CloudFormation deployment..."
                    python3 jenkins-data-pipeline/deploy.py \
                        packaged.yaml \
                        ${STACK_NAME} \
                        ${AWS_REGION} \
                        ${ENVIRONMENT}
                    
                    echo "âœ… Deployment command sent!"
                '''
            }
        }
        
        stage('Post-Deploy Validation') {
            steps {
                echo 'âœ… Validating deployment...'
                sh '''
                    echo "Checking CloudFormation stack status..."
                    sleep 5
                    
                    python3 << 'PYTHON_EOF'
import boto3
import json
from botocore.exceptions import ClientError

try:
    cf = boto3.client('cloudformation', region_name='${AWS_REGION}')
    stacks = cf.describe_stacks(StackName='${STACK_NAME}')
    stack = stacks['Stacks'][0]
    
    print(f"Stack Status: {stack['StackStatus']}")
    if 'Outputs' in stack:
        print("\nStack Outputs:")
        for output in stack['Outputs']:
            print(f"  {output['OutputKey']}: {output['OutputValue']}")
    else:
        print("\nNo outputs found in stack (stack may still be deploying)")
except ClientError as e:
    print(f"Stack not found or error: {e}")
except Exception as e:
    print(f"Error: {e}")
PYTHON_EOF
                '''
            }
        }
    }
    
    post {
        success {
            echo 'âœ… Pipeline completed successfully!'
            echo 'Your data pipeline is ready for use.'
        }
        failure {
            echo 'âŒ Pipeline failed. Check logs above.'
        }
    }
}
